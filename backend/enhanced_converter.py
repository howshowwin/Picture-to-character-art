import numpy as np
from PIL import Image, ImageEnhance, ImageFilter, ImageOps
import cv2
from typing import List, Tuple, Optional, Dict, Union
import colorsys
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor
import threading

# æ“´å±•çš„å­—å…ƒé›†åˆï¼ˆå¾äº®åˆ°æš—æ’åˆ— - é»‘è‰²æ˜ å°„åˆ°ç©ºç™½ï¼Œç™½è‰²æ˜ å°„åˆ°ç­†ç•«æœ€å¤šçš„å­—å…ƒï¼‰
CHARACTER_SETS = {
    "block": [' ', '.', "'", '`', ':', 'â–‘', 'â–’', 'â–“', 'â–ˆ'],
    "ascii": [" ", ".", ",", ":", ";", "+", "*", "?", "%", "S", "#", "@"],
    "extended_ascii": [' ', '.', 'Â·', ':', '!', '+', '*', 'x', '%', '#', 'W', '@'],
    "japanese": ['ã€€', 'ã€‚', 'ã€', 'ã¤', 'ã®', 'ã‚‹', 'ãŠ', 'æ„›', 'é›²', 'é¾', 'é—‡'],
    "chinese": ['ã€€', 'ä¸€', 'å', 'å£', 'æ—¥', 'ç›®', 'ç”°', 'åœ–', 'åœ‹', 'åœ“', 'é¬±'],
    "chinese_simple": ['ã€€', 'ä¸€', 'äºŒ', 'ä¸‰', 'ç‹', 'ä¸»', 'å›½', 'å›¾', 'åœ†', 'é»‘', 'å¢¨'],
    "braille": ['â €', 'â ', 'â ƒ', 'â ‡', 'â ', 'â Ÿ', 'â ¿', 'â¡¿', 'â£¿'],
    "shade": [' ', 'â–‘', 'â–’', 'â–“', 'â–ˆ'],
    "geometric": [' ', 'â–¸', 'â–¹', 'â—‚', 'â—ƒ', 'â—†', 'â—‡', 'â—ˆ', 'â—‰', 'â—', 'â– '],
    "emoji": ['â¬œ', 'ğŸŸ¨', 'ğŸŸ§', 'ğŸŸ¥', 'ğŸŸª', 'ğŸŸ¦', 'ğŸŸ©', 'ğŸŸ«', 'â¬›'],
    "custom_art": [' ', '.', 'o', 'O', '0', '@', '#', '&', '%', '$', 'M', 'W'],
}

# å­—å…ƒå¯†åº¦æ˜ å°„ï¼ˆç”¨æ–¼æ›´æº–ç¢ºçš„äº®åº¦è¡¨ç¤ºï¼‰
CHARACTER_DENSITY = {
    ' ': 0.0,
    '.': 0.1,
    ',': 0.1,
    "'": 0.05,
    '`': 0.05,
    ':': 0.2,
    ';': 0.2,
    '!': 0.3,
    '+': 0.4,
    '*': 0.5,
    'x': 0.6,
    '%': 0.7,
    '#': 0.8,
    '@': 0.9,
    'W': 0.95,
    'M': 1.0,
    'â–‘': 0.3,
    'â–’': 0.6,
    'â–“': 0.8,
    'â–ˆ': 1.0,
}

@dataclass
class ConversionOptions:
    """è½‰æ›é¸é …é…ç½®"""
    width: int = 100
    art_type: str = "block"
    color_mode: str = "grayscale"  # grayscale, ansi, ansi256, truecolor, html
    contrast: float = 1.0
    brightness: float = 1.0
    edge_detection: bool = False
    edge_threshold: int = 100
    denoise: bool = False
    sharpen: bool = False
    invert: bool = False
    dithering: bool = False
    custom_chars: Optional[str] = None
    
class ColorPalette:
    """ANSI è‰²å½©èª¿è‰²æ¿"""
    ANSI_COLORS = {
        'black': (0, 0, 0),
        'red': (205, 49, 49),
        'green': (13, 188, 121),
        'yellow': (229, 229, 16),
        'blue': (36, 114, 200),
        'magenta': (188, 63, 188),
        'cyan': (17, 168, 205),
        'white': (229, 229, 229),
    }
    
    @staticmethod
    def get_ansi_color(r: int, g: int, b: int) -> str:
        """ç²å–æœ€æ¥è¿‘çš„ ANSI é¡è‰²ç¢¼"""
        min_distance = float('inf')
        closest_color = 'white'
        
        for color_name, (cr, cg, cb) in ColorPalette.ANSI_COLORS.items():
            distance = ((r - cr) ** 2 + (g - cg) ** 2 + (b - cb) ** 2) ** 0.5
            if distance < min_distance:
                min_distance = distance
                closest_color = color_name
        
        return closest_color
    
    @staticmethod
    def get_ansi256_color(r: int, g: int, b: int) -> int:
        """è½‰æ› RGB åˆ° ANSI 256 è‰²"""
        # ç°éš
        if r == g == b:
            if r < 8:
                return 16
            elif r > 248:
                return 231
            else:
                return round(((r - 8) / 247) * 24) + 232
        
        # å½©è‰²
        r = 5 * round(r / 255 * 5)
        g = 5 * round(g / 255 * 5)
        b = 5 * round(b / 255 * 5)
        return 16 + (36 * (r // 51)) + (6 * (g // 51)) + (b // 51)

class EnhancedImageConverter:
    """å¢å¼·ç‰ˆåœ–ç‰‡è½‰æ›å™¨"""
    
    def __init__(self, options: ConversionOptions):
        self.options = options
        self._setup_character_set()
    
    def _setup_character_set(self):
        """è¨­ç½®å­—å…ƒé›†"""
        if self.options.custom_chars:
            self.chars = list(self.options.custom_chars)
        else:
            self.chars = CHARACTER_SETS.get(self.options.art_type, CHARACTER_SETS["block"])
        
        # æ ¹æ“šå­—å…ƒå¯†åº¦æ’åºï¼ˆå¦‚æœæœ‰å®šç¾©çš„è©±ï¼‰
        self.char_densities = []
        for char in self.chars:
            density = CHARACTER_DENSITY.get(char, len(self.char_densities) / len(self.chars))
            self.char_densities.append(density)
    
    def preprocess_image(self, image: Image.Image) -> Image.Image:
        """å½±åƒå‰è™•ç†"""
        # è½‰æ›ç‚º RGBï¼ˆå¦‚æœéœ€è¦ï¼‰
        if image.mode != 'RGB' and self.options.color_mode != 'grayscale':
            image = image.convert('RGB')
        
        # é™å™ª
        if self.options.denoise:
            image = image.filter(ImageFilter.MedianFilter(size=3))
        
        # éŠ³åŒ–
        if self.options.sharpen:
            image = image.filter(ImageFilter.SHARPEN)
        
        # èª¿æ•´å°æ¯”åº¦
        if self.options.contrast != 1.0:
            enhancer = ImageEnhance.Contrast(image)
            image = enhancer.enhance(self.options.contrast)
        
        # èª¿æ•´äº®åº¦
        if self.options.brightness != 1.0:
            enhancer = ImageEnhance.Brightness(image)
            image = enhancer.enhance(self.options.brightness)
        
        # åè½‰é¡è‰²
        if self.options.invert:
            if image.mode == 'L':
                image = ImageOps.invert(image)
            else:
                image = ImageOps.invert(image.convert('RGB'))
        
        return image
    
    def apply_edge_detection(self, image: np.ndarray) -> np.ndarray:
        """æ‡‰ç”¨é‚Šç·£åµæ¸¬"""
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        else:
            gray = image
        
        # ä½¿ç”¨ Canny é‚Šç·£åµæ¸¬
        edges = cv2.Canny(gray, self.options.edge_threshold, self.options.edge_threshold * 2)
        
        # åè½‰é‚Šç·£ï¼ˆè®“é‚Šç·£è®Šæˆç™½è‰²ï¼‰
        edges = 255 - edges
        
        return edges
    
    def apply_dithering(self, image: np.ndarray) -> np.ndarray:
        """æ‡‰ç”¨æŠ–å‹•ç®—æ³•ï¼ˆFloyd-Steinbergï¼‰"""
        if len(image.shape) == 3:
            # è½‰æ›ç‚ºç°åº¦
            gray = np.dot(image[...,:3], [0.2989, 0.5870, 0.1140])
        else:
            gray = image.copy()
        
        # è½‰æ›ç‚º float é¿å…æº¢å‡º
        gray = gray.astype(np.float64)
        h, w = gray.shape
        
        for y in range(h):
            for x in range(w):
                old_pixel = gray[y, x]
                new_pixel = 255.0 if old_pixel > 128 else 0.0
                gray[y, x] = new_pixel
                error = old_pixel - new_pixel
                
                # åˆ†é…èª¤å·®åˆ°å‘¨åœåƒç´ 
                if x + 1 < w:
                    gray[y, x + 1] = np.clip(gray[y, x + 1] + error * 7 / 16, 0, 255)
                if y + 1 < h:
                    if x > 0:
                        gray[y + 1, x - 1] = np.clip(gray[y + 1, x - 1] + error * 3 / 16, 0, 255)
                    gray[y + 1, x] = np.clip(gray[y + 1, x] + error * 5 / 16, 0, 255)
                    if x + 1 < w:
                        gray[y + 1, x + 1] = np.clip(gray[y + 1, x + 1] + error * 1 / 16, 0, 255)
        
        return gray.astype(np.uint8)
    
    def get_char_for_pixel(self, pixel_value: Union[int, np.ndarray]) -> Tuple[str, Optional[str]]:
        """æ ¹æ“šåƒç´ å€¼ç²å–å°æ‡‰å­—å…ƒå’Œé¡è‰²"""
        if isinstance(pixel_value, np.ndarray) and len(pixel_value) == 3:
            # RGB åƒç´ 
            r, g, b = pixel_value
            # è¨ˆç®—äº®åº¦ï¼ˆä½¿ç”¨æ„ŸçŸ¥äº®åº¦å…¬å¼ï¼‰
            brightness = 0.2989 * float(r) + 0.5870 * float(g) + 0.1140 * float(b)
        else:
            # ç°åº¦åƒç´ 
            brightness = float(pixel_value)
            r = g = b = int(pixel_value)
        
        # ç¢ºä¿äº®åº¦åœ¨æœ‰æ•ˆç¯„åœå…§
        brightness = max(0.0, min(255.0, brightness))
        
        # å°‡äº®åº¦æ˜ å°„åˆ°å­—å…ƒç´¢å¼•
        # é»‘è‰²ï¼ˆäº®åº¦0ï¼‰-> ç´¢å¼•0ï¼ˆç©ºç™½ï¼‰
        # ç™½è‰²ï¼ˆäº®åº¦255ï¼‰-> æœ€å¾Œç´¢å¼•ï¼ˆç­†ç•«æœ€å¤šçš„å­—å…ƒï¼‰
        normalized_brightness = brightness / 255.0
        char_index = int(normalized_brightness * (len(self.chars) - 1))
        char_index = max(0, min(len(self.chars) - 1, char_index))
        char = self.chars[char_index]
        
        # ç²å–é¡è‰²è³‡è¨Š
        color_code = None
        if self.options.color_mode != "grayscale":
            if self.options.color_mode == "ansi":
                color_code = ColorPalette.get_ansi_color(r, g, b)
            elif self.options.color_mode == "ansi256":
                color_code = ColorPalette.get_ansi256_color(r, g, b)
            elif self.options.color_mode in ["truecolor", "html"]:
                color_code = (r, g, b)
        
        return char, color_code
    
    def convert_to_art(self, image_path: str) -> Dict[str, any]:
        """è½‰æ›åœ–ç‰‡ç‚ºå­—å…ƒè—è¡“"""
        # è¼‰å…¥åœ–ç‰‡
        image = Image.open(image_path)
        
        # å‰è™•ç†
        image = self.preprocess_image(image)
        
        # è¨ˆç®—æ–°å°ºå¯¸
        aspect_ratio = image.height / image.width
        height = int(self.options.width * aspect_ratio * 0.55)
        
        # èª¿æ•´å¤§å°
        image = image.resize((self.options.width, height), Image.Resampling.LANCZOS)
        
        # è½‰æ›ç‚º numpy é™£åˆ—
        if self.options.color_mode == "grayscale" or image.mode == 'L':
            if image.mode != 'L':
                image = image.convert('L')
            pixels = np.array(image)
        else:
            if image.mode != 'RGB':
                image = image.convert('RGB')
            pixels = np.array(image)
        
        # é‚Šç·£åµæ¸¬
        if self.options.edge_detection:
            pixels = self.apply_edge_detection(pixels)
        
        # æŠ–å‹•
        if self.options.dithering:
            pixels = self.apply_dithering(pixels)
        
        # è½‰æ›ç‚ºå­—å…ƒè—è¡“
        art_lines = []
        color_data = []
        
        for row in pixels:
            line = ""
            row_colors = []
            
            for pixel in row:
                char, color = self.get_char_for_pixel(pixel)
                line += char
                row_colors.append(color)
            
            art_lines.append(line)
            if self.options.color_mode != "grayscale":
                color_data.append(row_colors)
        
        result = {
            "art": art_lines,
            "width": self.options.width,
            "height": height,
            "color_mode": self.options.color_mode,
        }
        
        if color_data:
            result["colors"] = color_data
        
        return result

class EnhancedVideoConverter:
    """å¢å¼·ç‰ˆå½±ç‰‡è½‰æ›å™¨"""
    
    def __init__(self, options: ConversionOptions, num_threads: int = 4):
        self.options = options
        self.num_threads = num_threads
        self.frame_converter = EnhancedImageConverter(options)
        self._frame_cache = {}
        self._cache_lock = threading.Lock()
    
    def _process_frame(self, frame: np.ndarray, frame_number: int) -> Dict[str, any]:
        """è™•ç†å–®ä¸€å¹€"""
        # æª¢æŸ¥ç·©å­˜
        with self._cache_lock:
            if frame_number in self._frame_cache:
                return self._frame_cache[frame_number]
        
        # è½‰æ›ç‚º PIL Image
        if len(frame.shape) == 2:
            pil_image = Image.fromarray(frame, mode='L')
        else:
            # OpenCV ä½¿ç”¨ BGRï¼Œéœ€è¦è½‰æ›ç‚º RGB
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(rgb_frame, mode='RGB')
        
        # å‰è™•ç†
        pil_image = self.frame_converter.preprocess_image(pil_image)
        
        # èª¿æ•´å¤§å°
        aspect_ratio = pil_image.height / pil_image.width
        height = int(self.options.width * aspect_ratio * 0.55)
        pil_image = pil_image.resize((self.options.width, height), Image.Resampling.LANCZOS)
        
        # è½‰æ›ç‚º numpy é™£åˆ—
        if self.options.color_mode == "grayscale":
            if pil_image.mode != 'L':
                pil_image = pil_image.convert('L')
            pixels = np.array(pil_image)
        else:
            if pil_image.mode != 'RGB':
                pil_image = pil_image.convert('RGB')
            pixels = np.array(pil_image)
        
        # æ‡‰ç”¨ç‰¹æ•ˆ
        if self.options.edge_detection:
            pixels = self.frame_converter.apply_edge_detection(pixels)
        
        if self.options.dithering:
            pixels = self.frame_converter.apply_dithering(pixels)
        
        # è½‰æ›ç‚ºå­—å…ƒè—è¡“
        art_lines = []
        color_data = []
        
        for row in pixels:
            line = ""
            row_colors = []
            
            for pixel in row:
                char, color = self.frame_converter.get_char_for_pixel(pixel)
                line += char
                row_colors.append(color)
            
            art_lines.append(line)
            if self.options.color_mode != "grayscale":
                color_data.append(row_colors)
        
        result = {
            "art": art_lines,
            "colors": color_data if color_data else None
        }
        
        # ç·©å­˜çµæœ
        with self._cache_lock:
            self._frame_cache[frame_number] = result
            # é™åˆ¶ç·©å­˜å¤§å°
            if len(self._frame_cache) > 100:
                oldest_key = min(self._frame_cache.keys())
                del self._frame_cache[oldest_key]
        
        return result
    
    def convert_video(self, video_path: str, fps: int = 24) -> Tuple[List[Dict], float, int]:
        """è½‰æ›å½±ç‰‡ç‚ºå­—å…ƒè—è¡“åºåˆ—"""
        cap = cv2.VideoCapture(video_path)
        
        if not cap.isOpened():
            raise Exception("ç„¡æ³•é–‹å•Ÿå½±ç‰‡æª”æ¡ˆ")
        
        # ç²å–å½±ç‰‡è³‡è¨Š
        original_fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = total_frames / original_fps
        
        # è¨ˆç®—å¹€é–“éš”
        frame_interval = max(1, int(original_fps / fps))
        
        frames_data = []
        frame_numbers = []
        frames_to_process = []
        
        # æ”¶é›†éœ€è¦è™•ç†çš„å¹€
        frame_number = 0
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            if frame_number % frame_interval == 0:
                frames_to_process.append((frame_number, frame.copy()))
                frame_numbers.append(frame_number)
            
            frame_number += 1
        
        cap.release()
        
        # ä½¿ç”¨å¤šåŸ·è¡Œç·’è™•ç†å¹€
        with ThreadPoolExecutor(max_workers=self.num_threads) as executor:
            futures = []
            for idx, (frame_num, frame) in enumerate(frames_to_process):
                future = executor.submit(self._process_frame, frame, idx)
                futures.append((idx, frame_num, future))
            
            # æ”¶é›†çµæœ
            for idx, frame_num, future in futures:
                result = future.result()
                timestamp = frame_num / original_fps
                
                frame_data = {
                    "frame_number": idx,
                    "timestamp": round(timestamp, 3),
                    "art": result["art"]
                }
                
                if result.get("colors"):
                    frame_data["colors"] = result["colors"]
                
                frames_data.append(frame_data)
        
        # æŒ‰å¹€è™Ÿæ’åº
        frames_data.sort(key=lambda x: x["frame_number"])
        
        return frames_data, duration, len(frames_data)